# core/management/commands/generate_daily_set.py
import os
import json
import random
from datetime import date as date_cls
from decimal import Decimal

from django.core.management.base import BaseCommand
from django.utils import timezone

from core.models import DailySet, ApiUsageLog
from core.usage import estimate_cost

from core.metrics import (   # ğŸ‘ˆ ì´ ì¤„ ì¶”ê°€
    DAILYSET_EVENTS_TOTAL,
    OPENAI_REQUESTS_TOTAL,
    OPENAI_TOKENS_TOTAL,
)

import traceback


# ==========================
# 1. í† í”½ ì¹´íƒˆë¡œê·¸ / í”„ë¡¬í”„íŠ¸
# ==========================

# ë‹¤ì–‘í•œ ì¥ë©´ì„ ë¯¸ë¦¬ ì •ì˜í•´ ë‘ê³  ë‚ ì§œ ê¸°ë°˜ìœ¼ë¡œ ê³¨ë¼ ì“´ë‹¤.
TOPIC_CATALOG = [
    # ì—…ë¬´ / íšŒì˜
    {
        "code": "scrum_planning",
        "jp_topic": "ã‚¹ãƒ—ãƒªãƒ³ãƒˆè¨ˆç”»ä¼šè­°",
        "ko_desc": "ìŠ¤í”„ë¦°íŠ¸ ê³„íš íšŒì˜",
        "category": "business_meeting",
        "tags": ["íšŒì˜", "ê°œë°œ", "ìŠ¤í¬ëŸ¼"],
    },
    {
        "code": "one_on_one",
        "jp_topic": "ï¼‘å¯¾ï¼‘ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é¢è«‡",
        "ko_desc": "1:1 í”¼ë“œë°± ë©´ë‹´",
        "category": "business_meeting",
        "tags": ["í”¼ë“œë°±", "ì»¤ë¦¬ì–´", "ë©˜í† ë§"],
    },
    {
        "code": "online_meeting",
        "jp_topic": "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä¼šè­°ã®é€²è¡Œ",
        "ko_desc": "ì˜¨ë¼ì¸ íšŒì˜ ì§„í–‰",
        "category": "business_meeting",
        "tags": ["ì˜¨ë¼ì¸", "íšŒì˜"],
    },

    # íšŒì‚¬ ìƒí™œ / ì¡ë‹´
    {
        "code": "office_smalltalk",
        "jp_topic": "ã‚ªãƒ•ã‚£ã‚¹ã§ã®ä½•æ°—ãªã„é›‘è«‡",
        "ko_desc": "ì‚¬ë¬´ì‹¤ì—ì„œì˜ ê°€ë²¼ìš´ ì¡ë‹´",
        "category": "office_life",
        "tags": ["ì¡ë‹´", "ë™ë£Œ", "ìŠ¤ëª°í† í¬"],
    },
    {
        "code": "after_work",
        "jp_topic": "ä»•äº‹çµ‚ã‚ã‚Šã®é£²ã¿ä¼š",
        "ko_desc": "í‡´ê·¼ í›„ íšŒì‹",
        "category": "office_life",
        "tags": ["íšŒì‹", "ë™ë£Œ", "ìˆ ìë¦¬"],
    },

    # ë³‘ì› / ê±´ê°•
    {
        "code": "hospital_checkup",
        "jp_topic": "ç—…é™¢ã§ã®å¥åº·è¨ºæ–­",
        "ko_desc": "ë³‘ì› ê±´ê°•ê²€ì§„",
        "category": "hospital",
        "tags": ["ê±´ê°•", "ë³‘ì›", "ì§„ë£Œ"],
    },
    {
        "code": "pharmacy",
        "jp_topic": "è–¬å±€ã§ã®è–¬ã®ç›¸è«‡",
        "ko_desc": "ì•½êµ­ì—ì„œ ì•½ ìƒë‹´",
        "category": "hospital",
        "tags": ["ì•½êµ­", "ìƒë‹´"],
    },

    # ìŒì‹ì 
    {
        "code": "restaurant_lunch",
        "jp_topic": "ç¤¾å“¡é£Ÿå ‚ã§ã®ãƒ©ãƒ³ãƒæ³¨æ–‡",
        "ko_desc": "ì‚¬ë‚´ ì‹ë‹¹ ì ì‹¬ ì£¼ë¬¸",
        "category": "restaurant",
        "tags": ["ì ì‹¬", "ì£¼ë¬¸", "ìŒì‹"],
    },
    {
        "code": "izakaya",
        "jp_topic": "å±…é…’å±‹ã§ã®æ³¨æ–‡ã¨ä¼šè¨ˆ",
        "ko_desc": "ì´ìì¹´ì•¼ì—ì„œ ì£¼ë¬¸ê³¼ ê³„ì‚°",
        "category": "restaurant",
        "tags": ["ìˆ ì§‘", "ì£¼ë¬¸", "ê³„ì‚°"],
    },

    # ì‡¼í•‘ / ì•…ê¸°
    {
        "code": "music_shop",
        "jp_topic": "æ¥½å™¨åº—ã§ã®ãƒ™ãƒ¼ã‚¹è³¼å…¥ç›¸è«‡",
        "ko_desc": "ì•…ê¸°ì ì—ì„œ ë² ì´ìŠ¤ ìƒë‹´",
        "category": "shopping",
        "tags": ["ì•…ê¸°", "ë² ì´ìŠ¤", "ì‡¼í•‘"],
    },
    {
        "code": "department_store",
        "jp_topic": "ãƒ‡ãƒ‘ãƒ¼ãƒˆã§ã®æœé¸ã³",
        "ko_desc": "ë°±í™”ì ì—ì„œ ì˜· ê³ ë¥´ê¸°",
        "category": "shopping",
        "tags": ["íŒ¨ì…˜", "ì‡¼í•‘"],
    },

    # ì—¬í–‰
    {
        "code": "hotel_checkin",
        "jp_topic": "ãƒ›ãƒ†ãƒ«ã§ã®ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³",
        "ko_desc": "í˜¸í…” ì²´í¬ì¸",
        "category": "travel",
        "tags": ["ì—¬í–‰", "í˜¸í…”"],
    },
    {
        "code": "train_station",
        "jp_topic": "é§…ã§ã®ä¹—ã‚Šæ›ãˆæ¡ˆå†…",
        "ko_desc": "ì—­ì—ì„œ í™˜ìŠ¹ ì•ˆë‚´ ë°›ê¸°",
        "category": "travel",
        "tags": ["êµí†µ", "ê¸°ì°¨", "ê¸¸ì°¾ê¸°"],
    },

    # ìŠ¤í¬ì¸  / ì·¨ë¯¸
    {
        "code": "gym_training",
        "jp_topic": "ã‚¸ãƒ ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç›¸è«‡",
        "ko_desc": "í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™ ìƒë‹´",
        "category": "hobby_sport",
        "tags": ["ìš´ë™", "í—¬ìŠ¤"],
    },
    {
        "code": "sports_watch",
        "jp_topic": "åŒåƒšã¨è©¦åˆè¦³æˆ¦ã®è¨ˆç”»ã‚’ç«‹ã¦ã‚‹",
        "ko_desc": "ë™ë£Œì™€ ê²½ê¸° ê´€ëŒ ê³„íš ì„¸ìš°ê¸°",
        "category": "hobby_sport",
        "tags": ["ìŠ¤í¬ì¸ ", "ê´€ëŒ", "ì•½ì†"],
    },

    # ê°ì • / ì¸ê°„ê´€ê³„
    {
        "code": "say_no_politely",
        "jp_topic": "ä¾é ¼ã‚’ä¸å¯§ã«æ–­ã‚‹è¡¨ç¾",
        "ko_desc": "ìš”ì²­ì„ ì •ì¤‘í•˜ê²Œ ê±°ì ˆí•˜ê¸°",
        "category": "communication",
        "tags": ["ê±°ì ˆ", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "ê°ì •"],
    },
    {
        "code": "appreciation",
        "jp_topic": "æ„Ÿè¬ã‚’ãã¡ã‚“ã¨ä¼ãˆã‚‹è¡¨ç¾",
        "ko_desc": "ê°ì‚¬ë¥¼ ì œëŒ€ë¡œ ì „ë‹¬í•˜ëŠ” í‘œí˜„",
        "category": "communication",
        "tags": ["ê°ì‚¬", "ì¹­ì°¬"],
    },

    # ê°€ì¡± / ì¼ìƒ
    {
        "code": "family_daily",
        "jp_topic": "å®¶æ—ã¨ã®æ—¥å¸¸ä¼šè©±",
        "ko_desc": "ê°€ì¡±ê³¼ì˜ ì¼ìƒ ëŒ€í™”",
        "category": "daily_life",
        "tags": ["ê°€ì¡±", "ì¼ìƒ"],
    },
    {
        "code": "weather_chat",
        "jp_topic": "å¤©æ°—ã®è©±é¡Œã§ä¼šè©±ã‚’å§‹ã‚ã‚‹",
        "ko_desc": "ë‚ ì”¨ ì´ì•¼ê¸°ë¡œ ëŒ€í™” ì‹œì‘í•˜ê¸°",
        "category": "daily_life",
        "tags": ["ë‚ ì”¨", "ìŠ¤ëª°í† í¬"],
    },
]

# ìš”ì¼ë³„ë¡œ ìš°ì„  ì‚¬ìš©í•  ì¹´í…Œê³ ë¦¬ ê·¸ë£¹
# 0=ì›”, 1=í™”, 2=ìˆ˜, 3=ëª©, 4=ê¸ˆ, 5=í† , 6=ì¼
WEEKDAY_CATEGORY_GROUPS = {
    0: ["business_meeting", "office_life"],          # ì›”: íšŒì˜/íšŒì‚¬ìƒí™œ
    1: ["office_life", "communication"],             # í™”: íšŒì‚¬ ìŠ¤ëª°í† í¬, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜
    2: ["hospital", "daily_life"],                   # ìˆ˜: ë³‘ì›/ê±´ê°• + ì¼ìƒ
    3: ["restaurant", "shopping"],                   # ëª©: ìŒì‹ì /ì‡¼í•‘
    4: ["business_meeting", "hobby_sport"],          # ê¸ˆ: íšŒì˜ + ìŠ¤í¬ì¸ /ì·¨ë¯¸
    5: ["travel", "hobby_sport"],                    # í† : ì—¬í–‰/ì·¨ë¯¸
    6: ["daily_life", "communication"],              # ì¼: ì¼ìƒ + ê°ì •/ê´€ê³„
}


SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯æ—¥æœ¬ã®ITä¼æ¥­ã§åƒããƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…¼ã€æ—¥æœ¬èªæ•™è‚²ã®å°‚é–€å®¶ã§ã™ã€‚"
    "ãƒ“ã‚¸ãƒã‚¹ç¾å ´ã ã‘ã§ãªãã€ç—…é™¢ãƒ»é£²é£Ÿåº—ãƒ»æ—…è¡Œãƒ»è²·ã„ç‰©ãƒ»ã‚¹ãƒãƒ¼ãƒ„ãƒ»æ„Ÿæƒ…è¡¨ç¾ãªã©"
    "ã•ã¾ã–ã¾ãªå ´é¢ã§ä½¿ãˆã‚‹è‡ªç„¶ãªæ—¥æœ¬èªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ•™ãˆã¾ã™ã€‚\n\n"
    "ã€å‡ºåŠ›å½¢å¼ã€‘\n"
    "å¿…ãš **JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ** ã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\n"
    "{\n"
    '  \"date\": \"YYYY-MM-DD\",                // ì˜¤ëŠ˜ ë‚ ì§œ\n'
    '  \"topic\": \"æ—¥æœ¬èªãƒˆãƒ”ãƒƒã‚¯ã®ã‚¿ã‚¤ãƒˆãƒ«\",     // ì¼ë³¸ì–´ ì£¼ì œ ì œëª©\n'
    "  \"sentences\": [                        // ì •í™•íˆ 5ë¬¸ì¥\n"
    "    {\"jp\": \"â€¦æ—¥æœ¬èªæ–‡â€¦\", \"ko\": \"â€¦í•œêµ­ì–´ ë²ˆì—­â€¦\"},\n"
    "    â€¦ åˆè¨ˆ5ã¤ â€¦\n"
    "  ],\n"
    "  \"meta\": {\n"
    "    \"level\": \"B1-B2\",                // ëŒ€ëµì ì¸ CEFR ë ˆë²¨\n"
    "    \"category\": \"business_meeting / daily_life / travel / hospital ãªã©\",\n"
    "    \"tags\": [\"íšŒì˜\", \"ì—¬í–‰\", \"ê°ì •\" ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰]\n"
    "  }\n"
    "}\n\n"
    "ã€ã‚¹ã‚¿ã‚¤ãƒ«æ¡ä»¶ã€‘\n"
    "ãƒ»æ–‡ä½“ã¯ã€åŸºæœ¬çš„ã«ä¸å¯§ä½“ï¼ˆã§ã™ï¼ã¾ã™èª¿ï¼‰ã€‚\n"
    "ãƒ»æ¼¢å­—ã«ã¯åˆç´šã€œä¸­ç´šå­¦ç¿’è€…ã‚’æ„è­˜ã—ã¦å¿…è¦ã«å¿œã˜ã¦ã²ã‚‰ãŒãªã‚’æ‹¬å¼§ã§è£œè¶³ã—ã¦ãã ã•ã„ã€‚\n"
    "  ä¾‹ï¼š ä¼šè­°(ã‹ã„ã), ä¾é ¼(ã„ã‚‰ã„) ãªã©ã€‚\n"
    "ãƒ»ê° ë¬¸ì¥ì€ ì‹¤ì œ íšŒí™”ì—ì„œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ì™„ê²°ëœ í•œ ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
    "ãƒ»í•œêµ­ì–´ ë²ˆì—­ì€ ì§ì—­ë³´ë‹¤ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ì¦ˆë‹ˆìŠ¤/ì¼ìƒ íšŒí™”ì²´ë¡œ ê°„ê²°í•˜ê²Œ ì¨ ì£¼ì„¸ìš”."
)


def _select_topic(target_date: date_cls, cli_topic: str):
    """
    - cli_topic ì´ 'auto'(ê¸°ë³¸)ë©´, ìš”ì¼ë³„ ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ ì•ˆì—ì„œ ë¡œí…Œì´ì…˜ìœ¼ë¡œ í† í”½ í•˜ë‚˜ ì„ íƒ.
    - cli_topic ì— ë¬¸ìì—´ì´ ë“¤ì–´ì˜¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ììœ  ì£¼ì œ ëª¨ë“œ).
    """
    # 1) ì‚¬ìš©ìê°€ ì§ì ‘ ì£¼ì œë¥¼ ì§€ì •í•œ ê²½ìš° â†’ auto ëª¨ë“œê°€ ì•„ë‹˜
    if cli_topic and cli_topic.lower() not in ("auto", "ìë™"):
        topic = cli_topic
        meta = {
            "category": "custom",
            "tags": ["custom"],
            "ko_desc": cli_topic,
        }
        return topic, meta

    # 2) auto ëª¨ë“œ: ìš”ì¼ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
    weekday = target_date.weekday()  # 0=ì›”, 6=ì¼
    cat_group = WEEKDAY_CATEGORY_GROUPS.get(weekday)

    # í˜¹ì‹œ ë§¤í•‘ì´ ì—†ìœ¼ë©´ ì „ì²´ ì¹´í…Œê³ ë¦¬ë¥¼ ì‚¬ìš©
    if not cat_group:
        cat_group = list({t["category"] for t in TOPIC_CATALOG})

    # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ê·¸ë£¹ ì•ˆì—ì„œë§Œ í† í”½ í›„ë³´ ì¶”ë¦¬ê¸°
    candidates = [t for t in TOPIC_CATALOG if t["category"] in cat_group]

    # ê·¸ë˜ë„ ë¹„ë©´ ì „ì²´ì—ì„œ ì‚¬ìš©
    if not candidates:
        candidates = TOPIC_CATALOG

    # 3) ë¡œí…Œì´ì…˜: ê¸°ì¤€ì¼ë¡œë¶€í„°ì˜ ì¼ìˆ˜ë¡œ ì¸ë±ìŠ¤ ê³„ì‚°
    base = date_cls(2025, 1, 1)  # ì„œë¹„ìŠ¤ ê¸°ì¤€ì¼ (ì›í•˜ë©´ ë°”ê¿”ë„ ë¨)
    delta_days = (target_date - base).days
    idx = delta_days % len(candidates)
    topic_def = candidates[idx]

    topic = topic_def["jp_topic"]
    meta = {
        "category": topic_def["category"],
        "tags": topic_def["tags"],
        "ko_desc": topic_def["ko_desc"],
        "code": topic_def["code"],
    }
    return topic, meta


def _build_user_prompt(date_str: str, topic: str, topic_meta: dict) -> str:
    """
    ëª¨ë¸ì—ê²Œ ì˜¤ëŠ˜ ë‚ ì§œ + ì„ íƒëœ í† í”½ + ì¥ë©´ ì •ë³´ë¥¼ ëª¨ë‘ ë„˜ê²¨ì¤€ë‹¤.
    """
    ko_desc = topic_meta.get("ko_desc", "")
    category = topic_meta.get("category", "")
    tags = ", ".join(topic_meta.get("tags", []))

    return (
        f"ì˜¤ëŠ˜ ë‚ ì§œëŠ” {date_str} ì…ë‹ˆë‹¤.\n"
        f"ì¥ë©´(category): {category}\n"
        f"í•œêµ­ì–´ ì„¤ëª…: {ko_desc}\n"
        f"ì¼ë³¸ì–´ í† í”½ ì œëª©: ã€Œ{topic}ã€ ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n"
        f"ê´€ë ¨ í‚¤ì›Œë“œ(tags): {tags}\n\n"
        "ìš”êµ¬ì‚¬í•­:\n"
        "1. ìœ„ ì¥ë©´ì„ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ì¼ë³¸ì¸ê³¼ ëŒ€í™”í•  ë•Œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"
        "2. ì •í™•íˆ 5ë¬¸ì¥ë§Œ ìƒì„±í•©ë‹ˆë‹¤.\n"
        "3. ê°€ëŠ¥í•œ í•œ ì„œë¡œ ë‹¤ë¥¸ ìƒí™©/ë‰˜ì•™ìŠ¤ë¥¼ ì„ì–´ì„œ, í‘œí˜„ì˜ í­ì´ ë„“ì–´ì§€ë„ë¡ í•´ ì£¼ì„¸ìš”.\n"
        "   - ì˜ˆ: ìš”ì²­, ì œì•ˆ, ì •ì¤‘í•œ ê±°ì ˆ, ì§ˆë¬¸, ê°ì‚¬ í‘œí˜„ ë“±\n"
        "4. ê° ë¬¸ì¥ì€ 1ë¬¸ì¥ìœ¼ë¡œ ì™„ê²°ë˜ë©°, ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ(2ì¤„ ì´ë‚´) ìœ ì§€í•´ ì£¼ì„¸ìš”.\n"
        "5. ìœ„ì—ì„œ ì„¤ëª…í•œ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€ì¼œ ì£¼ì„¸ìš”."
    )


def _fallback_dummy(date_str: str, topic: str, topic_meta: dict):
    """
    OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ë”ë¯¸ ë°ì´í„°.
    í† í”½/ë©”íƒ€ë„ í•¨ê»˜ ë°˜ì˜í•´ ë‘”ë‹¤.
    """
    return {
        "date": date_str,
        "topic": topic or "ã‚¹ãƒ—ãƒªãƒ³ãƒˆè¨ˆç”» ä¼šè­°",
        "sentences": [
            {
                "jp": "ä»Šæ—¥(ãã‚‡ã†)ã®è¨ˆç”»(ã‘ã„ã‹ã)ã‚’å…±æœ‰(ãã‚‡ã†ã‚†ã†)ã—ã¾ã™ã€‚",
                "ko": "ì˜¤ëŠ˜ ê³„íšì„ ê³µìœ í•˜ê² ìŠµë‹ˆë‹¤.",
            },
            {
                "jp": "é€²æ—(ã—ã‚“ã¡ã‚‡ã)ã‚’ç°¡æ½”(ã‹ã‚“ã‘ã¤)ã«å ±å‘Š(ã»ã†ã“ã)ã—ã¦ãã ã•ã„ã€‚",
                "ko": "ì§„ì²™ì„ ê°„ë‹¨íˆ ë³´ê³ í•´ì£¼ì„¸ìš”.",
            },
            {
                "jp": "å„ªå…ˆåº¦(ã‚†ã†ã›ã‚“ã©)ã‚’å†ç¢ºèª(ã•ã„ã‹ãã«ã‚“)ã—ã¾ã™ã€‚",
                "ko": "ìš°ì„ ìˆœìœ„ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.",
            },
            {
                "jp": "è¦‹ç©(ã¿ã¤ã‚‚)ã‚Šã®æ ¹æ‹ (ã“ã‚“ãã‚‡)ã‚’æ˜ç¢º(ã‚ã„ã‹ã)ã«ã—ã¾ã™ã€‚",
                "ko": "ê²¬ì ì˜ ê·¼ê±°ë¥¼ ëª…í™•íˆ í•˜ê² ìŠµë‹ˆë‹¤.",
            },
            {
                "jp": "æ‡¸å¿µç‚¹(ã‘ã­ã‚“ã¦ã‚“)ãŒã‚ã‚Œã°å…±æœ‰(ãã‚‡ã†ã‚†ã†)ã—ã¦ãã ã•ã„ã€‚",
                "ko": "ìš°ë ¤ ì‚¬í•­ì´ ìˆìœ¼ë©´ ê³µìœ í•´ì£¼ì„¸ìš”.",
            },
        ],
        "meta": {
            "level": "B1-B2",
            "category": topic_meta.get("category", "fallback"),
            "tags": topic_meta.get("tags", ["íšŒì˜", "ê°œë°œ", "ìŠ¤í”„ë¦°íŠ¸"]),
            "ko_desc": topic_meta.get("ko_desc", "ë”ë¯¸ ë°ì´í„°"),
        },
    }


# ==========================
# 2. Django ê´€ë¦¬ ëª…ë ¹
# ==========================

class Command(BaseCommand):
    help = "Generate and store today's 5 JP sentences (ë‹¤ì–‘í•œ ì¥ë©´, idempotent)"

    def add_arguments(self, parser):
        parser.add_argument(
            "--topic",
            default="auto",
            help="ì£¼ì œ. ê¸°ë³¸ê°’ 'auto' ëŠ” ë‚ ì§œë³„ë¡œ ìë™ ì„ íƒ. "
                 "ì§ì ‘ ì…ë ¥í•˜ë©´ í•´ë‹¹ ë¬¸ìì—´ì„ ì£¼ì œë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        )
        parser.add_argument(
            "--date",
            default=None,
            help="YYYY-MM-DD ë¡œ íŠ¹ì • ë‚ ì§œ ìƒì„±",
        )
        parser.add_argument(
            "--force",
            action="store_true",
            help="ì´ë¯¸ ìˆì–´ë„ ì¬ìƒì„±(ê¸°ì¡´ ë ˆì½”ë“œ ë®ì–´ì”€)",
        )

    def handle(self, *args, **opts):
        # ë‚ ì§œ ê²°ì •
        if opts.get("date"):
            try:
                target_date = date_cls.fromisoformat(opts["date"])
            except ValueError:
                self.stdout.write(self.style.ERROR("Invalid --date. Use YYYY-MM-DD"))
                return
        else:
            target_date = timezone.localdate()

        # í† í”½/ë©”íƒ€ ì„ íƒ
        cli_topic = opts["topic"]
        topic, topic_meta = _select_topic(target_date, cli_topic)
        force = bool(opts.get("force"))

        model_name = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        exists = DailySet.objects.filter(date=target_date).exists()
        if exists and not force:
            self.stdout.write(self.style.WARNING(f"Already exists for {target_date}"))
            return
        if exists and force:
            DailySet.objects.filter(date=target_date).delete()
            ApiUsageLog.objects.filter(date=target_date, model=model_name).delete()

        api_key = os.getenv("OPENAI_API_KEY", "").strip()
        date_str = target_date.isoformat()

        # -----------------
        #  API í‚¤ ì—†ìŒ â†’ ë”ë¯¸
        # -----------------
        if not api_key:
            data = _fallback_dummy(date_str, topic, topic_meta)
            DailySet.objects.create(
                date=target_date,
                topic=data.get("topic", ""),
                payload=data,
            )
            ApiUsageLog.objects.create(
                date=target_date,
                model=model_name,
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0,
                cost_usd=Decimal("0"),
                meta={"reason": "no_api_key", "topic": topic, **topic_meta},
            )

            DAILYSET_EVENTS_TOTAL.labels(result="fallback_no_api_key").inc()

            self.stdout.write(self.style.SUCCESS("Generated (dummy, no OPENAI_API_KEY)"))
            return


        try:
            from openai import OpenAI

            client = OpenAI(api_key=api_key)

            msgs = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": _build_user_prompt(date_str, topic, topic_meta),
                },
            ]

            resp = client.chat.completions.create(
                model=model_name,
                messages=msgs,
                temperature=0.7,
                response_format={"type": "json_object"},
            )
            content = resp.choices[0].message.content
            data = json.loads(content)

            # ê°„ë‹¨ ê²€ì¦
            s = data.get("sentences", [])
            if not (isinstance(s, list) and len(s) == 5):
                raise ValueError("Invalid JSON format from model (sentences length != 5)")

            # meta í•©ì¹˜ê¸°
            meta = data.get("meta") or {}
            meta.setdefault("category", topic_meta.get("category"))
            meta.setdefault("tags", topic_meta.get("tags"))
            meta.setdefault("ko_desc", topic_meta.get("ko_desc"))
            data["meta"] = meta

            DailySet.objects.create(
                date=target_date,
                topic=data.get("topic", topic),
                payload=data,
            )

            usage = getattr(resp, "usage", None)
            prompt_tokens = getattr(usage, "prompt_tokens", 0) if usage else 0
            completion_tokens = getattr(usage, "completion_tokens", 0) if usage else 0
            total_tokens = (
                getattr(usage, "total_tokens", prompt_tokens + completion_tokens)
                if usage
                else (prompt_tokens + completion_tokens)
            )
            cost = estimate_cost(model_name, prompt_tokens, completion_tokens)

            ApiUsageLog.objects.create(
                date=target_date,
                model=model_name,
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens,
                cost_usd=cost,
                meta={"topic": topic, **topic_meta},
            )

            # ğŸ‘‡ ë©”íŠ¸ë¦­: OpenAI / DailySet ì •ìƒ ìƒì„±
            OPENAI_REQUESTS_TOTAL.labels(
                model=model_name,
                outcome="success",
            ).inc()

            OPENAI_TOKENS_TOTAL.labels(
                model=model_name, kind="prompt"
            ).inc(prompt_tokens)
            OPENAI_TOKENS_TOTAL.labels(
                model=model_name, kind="completion"
            ).inc(completion_tokens)
            OPENAI_TOKENS_TOTAL.labels(
                model=model_name, kind="total"
            ).inc(total_tokens)

            DAILYSET_EVENTS_TOTAL.labels(result="success").inc()

            self.stdout.write(
                self.style.SUCCESS(
                    f"Generated (OpenAI) tokens={total_tokens} cost=${cost}"
                )
            )
            return

        except Exception as e:
            # ğŸ” ì—¬ê¸°ì„œ ì§„ì§œ ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤ë°±ì„ ì°ì–´ ë³´ì
            tb = traceback.format_exc()
            # stdout/stderr ë‘˜ ë‹¤ UTF-8 ì´ì§€ë§Œ, í˜¹ì‹œ ëª¨ë¥¼ ì¸ì½”ë”© ì´ìŠˆë¥¼ ì¤„ì´ê¸° ìœ„í•´ repr ì‚¬ìš©
            self.stderr.write(self.style.ERROR("OpenAI call failed with exception:"))
            self.stderr.write(tb)

            # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ë¡œë¼ë„ ì €ì¥í•´ì„œ ì„œë¹„ìŠ¤ëŠ” ê³„ì† ë™ì‘
            data = _fallback_dummy(date_str, topic, topic_meta)
            DailySet.objects.create(
                date=target_date,
                topic=data.get("topic", ""),
                payload=data,
            )
            # ì—ëŸ¬ ë¬¸ìì—´ë„ reprë¡œ ì €ì¥ (ë¹„ ASCII ë¬¸ì ë•Œë¬¸ì— ë˜ í„°ì§€ëŠ” ê²ƒ ë°©ì§€)
            ApiUsageLog.objects.create(
                date=target_date,
                model=model_name,
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0,
                cost_usd=Decimal("0"),
                meta={"fallback_error": repr(e), "traceback": tb, "topic": topic, **topic_meta},
            )

            # ğŸ‘‡ ë©”íŠ¸ë¦­: OpenAI ì—ëŸ¬ + fallback
            OPENAI_REQUESTS_TOTAL.labels(
                model=model_name,
                outcome="error",
            ).inc()

            DAILYSET_EVENTS_TOTAL.labels(result="fallback_error").inc()

            self.stdout.write(
                self.style.WARNING("OpenAI failed, fallback dummy used (see stderr for traceback)")
            )